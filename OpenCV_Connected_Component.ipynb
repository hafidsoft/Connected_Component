{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Connected component labeling**\n",
        "Component labeling is basically extracting a region from the original image except that we try to find only the components which are “connected” which is determined by the application of the graph theory.\n",
        "\n"
      ],
      "metadata": {
        "id": "Yig-srbfRlh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1: Image Loading and Preprocessing"
      ],
      "metadata": {
        "id": "-flpMZZdRsTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s first load our image and convert it to a grayscale image, this makes the algorithm much more efficient and accurate."
      ],
      "metadata": {
        "id": "p5nW9ksLR1Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Loading the image\n",
        "img = cv2.imread('images/img5.png')\n",
        "\n",
        "# preprocess the image\n",
        "gray_img = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#cv2_imshow(gray_img)"
      ],
      "metadata": {
        "id": "R59sTa65R9Hf"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this we’ll also apply a 7×7 Gaussian blur, this helps to remove unwanted edges and helps in a much more clear segmentation, which we’ll do in the next step."
      ],
      "metadata": {
        "id": "hUA8_eAfSGGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying 7x7 Gaussian Blur\n",
        "blurred = cv2.GaussianBlur(gray_img, (7, 7), 0)\n",
        "\n",
        "#cv2_imshow(blurred)"
      ],
      "metadata": {
        "id": "WewOaBuVSM5P"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Thresholding\n",
        "Thresholding is a very basic image segmentation technique that helps us separate the background and the foreground objects that are of interest to us. After applying the blur we’ll use the cv2.threshold function for image segmentation."
      ],
      "metadata": {
        "id": "Xjld8kiASA2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying threshold\n",
        "threshold = cv2.threshold(blurred, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "#cv2_imshow(threshold)"
      ],
      "metadata": {
        "id": "ZlsvXTXdSAuw"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Applying the Component Analysis Method\n",
        "We first apply the cv2.connectedComponentsWithStats and then unpack the values it returns in different variables which we will use in the following steps, and let’s also create a new array to store all the components that we find.\n"
      ],
      "metadata": {
        "id": "ic6n-bU6SAif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Component analysis function\n",
        "analysis = cv2.connectedComponentsWithStats(threshold,\n",
        "\t\t\t\t\t\t\t\t\t\t\t4,\n",
        "\t\t\t\t\t\t\t\t\t\t\tcv2.CV_32S)\n",
        "(totalLabels, label_ids, values, centroid) = analysis\n",
        "\n",
        "# Initialize a new image to store\n",
        "# all the output components\n",
        "output = np.zeros(gray_img.shape, dtype=\"uint8\")\n",
        "\n",
        "#cv2_imshow(output)"
      ],
      "metadata": {
        "id": "DG2S5p9WTCCf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our components and analysis, let’s loop through each of the components and filter out the useful components."
      ],
      "metadata": {
        "id": "g5BvBR4-TB_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 4: Filter Out Useful Components\n",
        "Let’s loop through each of the components and use the statistics we got in the last step to filter out useful components. For example, here I have used the Area value to filter out only the characters in the image. And after filtering out the components, we’ll use the label_ids variable to create a mask for the component that we’re looping through and use the bitwise_or operation on the mask to generate our final output. It sounds hard, but you’ll understand it better after implementing the code yourself.\n"
      ],
      "metadata": {
        "id": "-QYEnC_tTNOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each component\n",
        "for i in range(1, totalLabels):\n",
        "    area = values[i, cv2.CC_STAT_AREA]  \n",
        "  \n",
        "    if (area > 140) and (area < 400):\n",
        "        \n",
        "        # Labels stores all the IDs of the components on the each pixel\n",
        "        # It has the same dimension as the threshold\n",
        "        # So we'll check the component\n",
        "        # then convert it to 255 value to mark it white\n",
        "        componentMask = (label_ids == i).astype(\"uint8\") * 255\n",
        "          \n",
        "        # Creating the Final output mask\n",
        "        output = cv2.bitwise_or(output, componentMask)\n",
        "\n"
      ],
      "metadata": {
        "id": "_c-1AZ0HSyq_"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 5: Visualize The Final Output\n",
        "Now our final step is to simply display our original image and the final mask that we obtained.\n"
      ],
      "metadata": {
        "id": "Le6uY8jCUAx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Original image\n",
        "cv2_imshow(img)\n",
        "#Filtered Components\n",
        "cv2_imshow(output)"
      ],
      "metadata": {
        "id": "BO1kvMG6Uf65"
      },
      "execution_count": 65,
      "outputs": []
    }
  ]
}